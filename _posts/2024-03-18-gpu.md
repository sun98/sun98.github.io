# GPU学习

基本原理：

- 流处理器架构 - GPU采用大量简单流处理器组成,利用单指令多数据(SIMD)架构实现大规模并行计算。
- 分支与掩码 - GPU流处理器采用隐式掩码实现分支,避免了分支导致的性能损失。
- 内存层级结构 - GPU具有显存和多级缓存,类似CPU,但更侧重于带宽而非容量。

## 硬件相关

### 架构

GPU硬件上主要包含以下部分：

- 流处理器阵列 - 大量流处理器集群,每个集群包含多个流处理器,用于并行计算。
- 指令单元 - 负责将指令发送到各个流处理器集群执行。
- 内存控制器 - 管理显存访问,保证高带宽。
- 缓存系统 - L1、L2等多级缓存加速内存访问。
- 固定功能硬件 - 用于渲染、视频解码等固定功能加速。

#### 流处理器

可运行的指令（具体的指令细节在不同平台上不同）：
- 算数：加减乘除、位运算
- 内存：从显存、缓存加载到寄存器，把寄存器数据存储到内存
- 流控制：跳转、循环
- 特殊功能：矩阵运算、纹理采样、视频编解码等

#### 指令单元

指令调度、指令分发、指令管理跟踪

#### 内存控制器

区别于CPU mem的是，GPU更在意显存带宽，而不是容量。GPU显存也有页表TLB、虚拟内存到物理内存映射

主要流程：
- 内存请求调度
- 内存通道仲裁
- 数据传输管理
- 页表管理
- 内存预取

#### 缓存系统（cache）

目的：缓解GPU对显存的带宽瓶颈

#### 固定功能硬件

## 软件相关

### 编程模型

#### 隐式掩码

- GPU将线程分组为线程束(warp)，每个线程束内的所有线程并发执行相同的指令序列（单指令多数据SIMD）。
- 每个线程内部通过条件代码跳过不应执行的条件路径。
- GPU流处理器为每个线程束维护一个活跃掩码(active mask),它跟踪哪些线程需要执行、哪些不需要执行。
- 对于线程束中被掩码禁用的线程,其ALU和内存操作将被无声地抑制,不会有任何影响。

### GPU驱动
